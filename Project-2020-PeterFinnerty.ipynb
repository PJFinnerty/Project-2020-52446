{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Fundamentals of Data Analysis\n",
    "\n",
    "## Project 2020 - Peter Finnerty\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "<br>\n",
    "In this project you must perform and explain simple linear regression using Python\n",
    "on the powerproduction dataset available on Moodle. \n",
    "\n",
    "The goal is to accurately predict wind turbine power output from wind speed values using the data set as a basis.\n",
    "\n",
    "Your submission must be in the form of a git repository containing, at a minimum, the\n",
    "following items:\n",
    "\n",
    "1. Jupyter notebook that performs simple linear regression on the data set.\n",
    "\n",
    "\n",
    "2. In that notebook, an explanation of your regression and an analysis of its accuracy.\n",
    "\n",
    "\n",
    "3. Standard items in a git repository such as a README.\n",
    "\n",
    "To enhance your submission, you might consider comparing simple linear regression to\n",
    "other types of regression on this data set. Rest assured, all the above concepts will be\n",
    "explored in lecture videos and other materials in the coming semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "# Contents\n",
    "\n",
    "***\n",
    "\n",
    "### 1. Overview of Regression Models\n",
    "\n",
    "#### 1.1. Defining Simple Linear Regression\n",
    "\n",
    "#### 1.2. Polynomial Regression\n",
    "\n",
    "#### 1.3. Methodology of Regression\n",
    "\n",
    "#### 1.4. Glossary of Regression Terms\n",
    "\n",
    "***\n",
    "\n",
    "### 2. The Powerproduction Dataset\n",
    "\n",
    "#### 2.1. Dataset Details\n",
    "\n",
    "#### 2.2. Distribution Plots of the Variables\n",
    "\n",
    "***\n",
    "\n",
    "### 3. Simple Linear Regression\n",
    "\n",
    "#### 3.1. Using np.polyfit() on Full Dataset\n",
    "\n",
    "* Results\n",
    "\n",
    "#### 3.2. Simple Linear Regression Using Sklearn\n",
    "\n",
    "* train_test_split Model for Simple Linear Regression\n",
    "\n",
    "* Scatterlot of Training Data and Test Data With Regression\n",
    "\n",
    "* Results of Sklearn Model of SLR\n",
    "\n",
    "* Advanced Results of Sklearn Model of SLR\n",
    "\n",
    "***\n",
    "\n",
    "### 4. Polynomial Linear Regression\n",
    "\n",
    "#### 4.1. Using curve_fit() Method on Full Dataset\n",
    "\n",
    "* Results of curve_fit() Method\n",
    "\n",
    "#### 4.2. Polynomial Regression Using Sklearn\n",
    "\n",
    "* Scatterplot of Polynomial Regression of Test/Training Dat\n",
    "\n",
    "* Results of Sklearn Polynomial Regression Model\n",
    "\n",
    "* Advanced Results of Sklearn Polynomial Regression Model\n",
    "\n",
    "### 5. Table of Results\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 1. Overview of Regression Concepts\n",
    "\n",
    "## 1.1. Defining Simple Linear Regression\n",
    "\n",
    "Algebraic Simultaneous Equations as studied in second level education, suggest that there is a linear relationship between input variables (x) and a single output variable (y) and that y can be calculation from a combination of x variables (MachineLearningMastery.com). \n",
    "\n",
    "At second level, Linear Regression is studied at the most basic level in the equation of a line as seen below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.pinimg.com/originals/d3/36/bd/d336bddce77d0769448561fde53b0372.jpg\" style=\"width: 450px;\">                                                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a useful basis from which to expand one's knowledge of Linear Regression, beyond the application in Algebra to Data Analysis and more specifically, to Simple Linear Regression on a Dataset.\n",
    "\n",
    "In the above formula, *m* is called the angular coefficient and *c* is the intercept. When we look at a dataset, and investigate all the vectors in terms of fitting a straight line, we are searching the values of *m* and *c* that provide the most appropriate position of the line (finxter.com).\n",
    "\n",
    "As a specific form of Regression, Simple Linear Regression deals with quantitative variables. More specifically, it is used to determine the strength of a relationship between two variables (such as rainfall and soil erosion) or, to determing the value of a dependent quantitative variable where a certain independent variable is known (scribbr.com).\n",
    "\n",
    "The basis of Simple Linear Regression is utising the coefficients of a set of data from 2 arrays, in order to draw a straight line through the data, whereby, the 'cost' is minimised. \n",
    "\n",
    "The cost is the combined distance of each y-vector from the Regression Line. A cost of 200, is much more desirible than a cost of 300, however, a cost of 0 is not possible.\n",
    "\n",
    "Therefore, Simply Linear Regression is defined as the positioning of the 'best fit' straight line though data.\n",
    "\n",
    "The picture below exemplifies this idea:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2584/1*Nf2tTTkALYq6RTMQmhjo1A.png\" style=\"width: 450px;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## 1.2. Defining Polynomial Regression\n",
    "\n",
    "\n",
    "### What is it?\n",
    "\n",
    "Polynomial Regression is is a type of regression analysis where the relationship between the independent variable (x) and dependent variable (y) are modelled as the *nth degree* in x.\n",
    "\n",
    "The word Polynomial comes from the Greek word 'poly' meaning many and the Latin word 'nomial' meaning terms. Therefore, it directly translates as 'many terms'. \n",
    "\n",
    "This applies to Polynomial Regression, whereby, the Polynomial equations that drive the analysis models contain a number of terms.\n",
    "\n",
    "This is demonstrated by the graph below, whereby a polynomial is presented that contains 3 terms, one cubic, one quadratic and one linear, as well as a leading coefficient and a constant.\n",
    "\n",
    "<img src=\"https://slideplayer.com/slide/14484666/90/images/7/%F0%9D%9F%91%F0%9D%92%99+%F0%9D%9F%91+%E2%88%92+%F0%9D%9F%93%F0%9D%92%99+%F0%9D%9F%90+%E2%88%92%F0%9D%9F%90%F0%9D%92%99%2B%F0%9D%9F%8F+Parts+of+a+polynomial+Cubic+term+Linear+term.jpg\" style=\"width: 450px;\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models produced by Polynomial Regression are non-linear as they produce estimations that do not fit a straight line. It fits a non-linear relationship between the value of x and the corresponding conditional mean of y, denoted as *E(y|x)* (i2tutorials). \n",
    "\n",
    "Despite fitting a non-linear model, Polynomial Regression operates as a linear statistical estimator. \n",
    "\n",
    "Furthermore, Polynomial Regression is a special case of Multiple Linear Regression. Another name for Polynomial Regression is curve fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "### What Does Curve Fitting Require?\n",
    "\n",
    "#### The Basis Function\n",
    "\n",
    "Curve fitting first requires creating the form of the *Mapping Function*, this is known as the *Basis Function*. \n",
    "\n",
    "To begin with, we do not yet know the form of the Mapping function that maps examples of inputs and outputs, but we can approximate it by creating the Basis function (Machine Learning Mastery).\n",
    "\n",
    "Once the Basis Function has been approximated, the parameters to the function can be identified that result in the least amount of error. \n",
    "\n",
    "By comparing the output from the Basis Function to the observed output, we can calculate the error.\n",
    "\n",
    "When there are two variables involved in a dataset, as there is with the Powerproduction Dataset, the independent variable will form the input of the Mapping function, whilst the dependent variable will form the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Methodolgy of Regression\n",
    "\n",
    "As previously described, this project involves two differenct types of regression: Simple Linear Regression (Section 3) and Polynomial Regression (Section 4). For each type of regression, there will be two different types of approach taken. \n",
    "\n",
    "The first approach will involve an example of bad-practice regression. This will be a non-model based approach, where the dataset is analysed in its entirety. The purpose of doing so will be to underline the basics of regression, whilst outlining how failing to split the data into training and test data can result in inaccuracies. \n",
    "\n",
    "The second type of regression will utilise accurate Sklearn models on training/split data. It will be a more complex, memory-consuming process, however, it will yield better results than the basic forms. \n",
    "\n",
    "Furthermore, it will provide for a wider range of statistics to indicate a successful regression of the data, such as the Standard Error of the Coefficient (Std. Err.), which can not accurately be created using the non-model approach.\n",
    "\n",
    "The way in which Sklearn splits data into training and test data is illustrated in the picture below.\n",
    "\n",
    "<img src=\"https://www.kdnuggets.com/wp-content/uploads/train_test_split.jpg\" style=\"width: 450px;\">\n",
    "\n",
    "*Image from KDnuggets*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## 1.4. Glossary of Regression Terms\n",
    "\n",
    "### Coefficients <span style=\"color: blue;\">(*coef*)</span>\n",
    "\n",
    "In the regression of a dataset, the coefficients describe the statistical relationship between the independent variables and the dependent variables.\n",
    "\n",
    "The sign of the coefficent can tell you the direction of the relatioship between the variables. A positive sign identifies that as the independent variable increases, the mean of the dependent variable also increases, whilst a negative sign suggests a decrease.\n",
    "\n",
    "The value of the coefficient describes how the mean of the dependent variable changes in relation to the independent variable.\n",
    "\n",
    "Whilst carrying out regression on an indepedent variable and a dependent variable, it is important to hold the other variables 'constant'. That is to say it is imperative to study the effect of the independent variable on each dependent variable in isolation from the others (statisticsbyjim.com).\n",
    "\n",
    "The coefficients of the output are estimates of the actual data population, therefore, it is important to ensure that the model for regression follows best practice for that particular type of regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "### Coefficient of Determination <span style=\"color: blue;\">*(R²)*</span>\n",
    "\n",
    "#### <span style=\"color: green;\">*High Percentage R² = Good fit; Low Percentage R² = Bad fit*</span>\n",
    "\n",
    "R² is the percentage of the response variable variation of a linear model. It measures how close the data are fitted by a line of regression (Frost, Statistics By Jim).\n",
    "\n",
    "R² is a valuable indicator for a Linear-regression model (including Polynomial models), however, it is important to check the test and training data of the model for signs of unwanted bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Standard Error of the Coefficient  <span style=\"color: blue;\">(*SE coef.* or *Std. Err.*)</span> and t-value  <span style=\"color: blue;\">(*t*)</span>\n",
    "\n",
    "#### <span style=\"color: green;\">*Std. Err: Low Values = Good fit; High Values = Bad fit*</span>\n",
    "\n",
    "#### <span style=\"color: brown;\">*t-value: High Values = Good fit; Low Values = Bad fit*</span>\n",
    "\n",
    "The Standard Error measures the accuracy of the unknown coefficient of the model. It is a floating point number that is always positive. The smaller the Std. Err. the more accurate the estimate is (Minitab.com). \n",
    "\n",
    "Dividing the coefficient by the standard error will produce a t-value or t-statistic. As a lower Std. Err. indicates lower error and the t-value calculates how many times the error divides into the coefficent itself, a larger t-value indicates greater accuracy. \n",
    "\n",
    "As a result, the t-value is essentially a measure of the error in relation to the coefficient.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-Values  <span style=\"color: blue;\">(*p*)</span>, the Null Hypothesis <span style=\"color: blue;\">(*H0*)</span> and the Significance Level  <span style=\"color: blue;\">(*α* or *alpha level*)</span>   \n",
    "\n",
    "#### <span style=\"color: green;\">*Good Fit: when p-value* < *Significance Level*, and H0 is rejected </span>\n",
    "\n",
    "P-values work together with Coefficients to indicate the statistical value produced in the Regression process. Specifically, the P-values *of* the coefficients identify whether the relationships observed in a sample exist throughout the population (StatisticsByJim). \n",
    "\n",
    "The p-value is a number between 0 and 1.\n",
    "\n",
    "For each independent variable, there is a possibility that the variable has no correlation to the dependent variable, in which case there is not enough proof to display a relationship. This lack of a relationship is known as the Null Hypothesis and the P-values can test for this.\n",
    "\n",
    "If it is first necessary to reject the Null Hypothesis in order to determine that there is a significant enough effect between the variables in your sample in order to conclude that the same effect is present in the wider population. The significance level is the probability of dismissing the Null Hypothesis when it in fact is evident.\n",
    "\n",
    "The Significane Level, is a pre-determined threshold. It is normally set to a value of 0.05 (5%). However, the researcher must identify an appropriate threshold of Significance Level, from which to compare to the p-value. \n",
    "\n",
    "If the P-value is less than the significance level, the Null Hypothesis can be sufficiently rejected.\n",
    "\n",
    "As the coefficients, P-values and the Significance level are determined for each variable in isolation, this can determine what variables should be included in the Regression analysis. \n",
    "    \n",
    "The Significance Level for this project will be set at 5%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "# 2. The Powerproduction Dataset \n",
    "\n",
    "## 2.1. Dataset Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset\n",
    "df = pd.read_csv(\"powerproduction.txt\")\n",
    "\n",
    "# Assign variables\n",
    "power = df[\"power\"]\n",
    "\n",
    "speed = df[\"speed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape\n",
    "\n",
    "The Powerproduction dataset has 2 columns and 500 rows, as demonstrated in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "### Variables\n",
    "\n",
    "The variables presented in the two columns are Speed and Power, with each containing 500 vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Speed variable relates to wind speed that affects the rate at which a wind turbine spins.\n",
    "\n",
    "The Power variable reflects the level of power produced at each observation of speed.\n",
    "\n",
    "***\n",
    "\n",
    "### Relationship Between Variables\n",
    "\n",
    "**Independent Variable:** Speed\n",
    "\n",
    "**Dependent Variable:** Power\n",
    "\n",
    "It is indeed intuitive that Speed is the Independent variable and that Power is the Dependent Variable, as we know from real-world logic that the rate of wind speed affects the level of power that is produced, but the power does **not** affect the wind Speed.\n",
    "\n",
    "By investigating the first 10 and last 15 rows of both variables, a number of key observations can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed.head(10), power.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Speed:** For almost every Speed observation, there is a consistent increase of 0.025(km/hour). There are a number if exceptions to this, such as from index 0, to index 1, which goes directly from 0.000 to 0.125.\n",
    "\n",
    "**Power:** The Power variable, indicates that no power is produced for the first 5 observations. When Speed reaches 0.325 however, power output jumps to 4.331."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speed.tail(15), power.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, at the tail end of the dataset, when Speed reaches 24.499, Power drops from 95.117, to 0. \n",
    "\n",
    "This reflects the way that turbine power production has a minimum and maximum wind speed required for the production of power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "### The Mean Value\n",
    "\n",
    "##### Independent Variable: Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_speed = sum(speed / float(len(speed)))\n",
    "mean_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is seen above the Mean value of the 'Speed' variable is **12.59**,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependent Variable: Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_power = sum(power) / float(len(power))\n",
    "mean_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean value of the Power variable is **48.01**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### The Variance\n",
    "\n",
    "Variance is the measure of the spread between numbers in a data set. In other words, it means how far each number in the set is from the mean (Dhiraj, K, 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to calculate the variance\n",
    "def variance(values, mean):\n",
    "    return sum([(i-mean)**2 for i in values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_speed, variance_power = variance(df[\"speed\"], mean_speed), variance(df['power'], mean_power)\n",
    "variance_speed , variance_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance of the Speed variable: **26048.05**.\n",
    "\n",
    "Variance of the Power variable: **864154.54**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Covariance\n",
    "\n",
    "Covariance is the measure of the directional relationship between two random variables. In other words, covariance measures how much two random variables vary together (Dhiraj, K, 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to calculate covariance between Speed and Power\n",
    "def covariance(speed, mean_speed, power , mean_power):\n",
    "    covariance = 0.0\n",
    "    for p in range(len(speed)):\n",
    "           covariance = covariance + (speed[p] - mean_speed) * (power[p] - mean_power)\n",
    "    return covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_speed_power = covariance(df['speed'],mean_speed,df['power'],mean_power)\n",
    "covariance_speed_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance between both variables: **128093.77**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### The Terms of the Linear Equation: Y = mX + c\n",
    "\n",
    "#### Y = Power (dependent variable)\n",
    "\n",
    "#### X = Speed (independent variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m is the slope *or* **the covariance of Power / the variance of Speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = covariance_speed_power/ variance_speed\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, **m = 4.918**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c is the constant *or* **mean of Power *  mean of Speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = mean_power - m * mean_speed\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, **c = -13.89**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## 2.2. Distribution Plots of the Variables\n",
    "\n",
    "In order to visualise the distribution of the variables, it is necessary to plot them separately, in univariate plots.\n",
    "\n",
    "#### Speed Distribution\n",
    "\n",
    "Looking below at the plot of the Speed variable, there is a near-uniform distribution of Speed vectors, reflecting the consistent spread of data that was previously noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_hist = sns.distplot(speed, bins=30)\n",
    "plt.xlabel(\"Speed\")\n",
    "plt.title(\"Distplot of Speed (Independent Variable)\")\n",
    "speed_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Distribution\n",
    "\n",
    "The concentration of Power data around on either side of the wind speed threshold is evident in the plot below. Around 0 and 100, there are peaks of Power vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_hist = sns.distplot(power, bins=30)\n",
    "plt.xlabel(\"Power\")\n",
    "plt.title(\"Distplot of Power (Dependent Variable)\")\n",
    "power_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## 3. Simple Linear Regression on Powerproduction Data\n",
    "\n",
    "The following section is split up into two sections. \n",
    "\n",
    "Section 3.1. outlines a basic form of Simple Linear Regression using Numpy's polyfit() function. This is not true regression, however, as no model has been created.\n",
    "\n",
    "Section 3.2. features the creation of a Linear Regression model using Scikit Learn. The dataset is first split into test and training data, before Simple Linear Regression is carried out and valuable data is produced in this process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## 3.1. Using np.polyfit() on the Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot below, the Speed and Power variables have been plotted in a bivariate plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot of Speed Vs. Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bivariate plot of speed vs power and format\n",
    "Plot_1 = plt.plot(speed, power, '.')\n",
    "plt.xlabel(\"Speed\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"Scatterplot of Speed Vs Power (Full Dataset)\")\n",
    "\n",
    "Plot_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the above graph, a curve is noticed in the data as Speed and Power increase. \n",
    "\n",
    "There is a strong concentration of vectors in the bottom left: 0-8 for Speed and 0-10 for Power. \n",
    "\n",
    "Furthermore, there is a concentration in the top right: 17-35 for Speed and 90-110 for Power. Infact it appears from simply looking at the plot that the majority of the vectors of the dataset are located in these two zones.\n",
    "\n",
    "In the scatterplot below, the Speed and Power data has been input into np.polyfit() and a degree of 1 has been assigned. Although polyfit() is not speciically designed for Simple Linear Regression, setting the parameter to 1 achieves this goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot with Regression Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatterplot and fornate\n",
    "Plot_2 = plt.plot(speed, power, '.')\n",
    "plt.xlabel(\"Speed\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"Variables with Polyfit() Regression Line\")\n",
    "\n",
    "# Sub in variables into polyfit() function with a degree of 1 (for straight line)\n",
    "coeffs = np.polyfit(speed, power, 1)\n",
    "\n",
    "# Print the coefficients of the straight line to the screen\n",
    "print(coeffs)\n",
    "\n",
    "# Plot the polyfit() variable factoring in both coefficient values\n",
    "plt.plot(speed, coeffs[0] * speed + coeffs[1], 'r-')\n",
    "\n",
    "Plot_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients\n",
    "\n",
    "**4.91759567, -13.89990263**\n",
    "\n",
    "#### R² of polyfit() Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.corrcoef to caluclate R²\n",
    "np.corrcoef(speed, power)[0, 1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously state, accurate regression requires the splitting up of data into test data and training data. This technique does not produce accurate results and has been included to highlight the necessity of using a reliable model.\n",
    "\n",
    "It has an R² of 72.9%.\n",
    "\n",
    "#### Conclusion: As this is not a Regression *Model*, the data cannot be said to fit, underfit or overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## 3.2. Carrying Out Simple Linear Regression Using Sklearn\n",
    "\n",
    "This section displays a more accurate method of Simple Linear Regression using Scikit Learn and the train_test_split() method for dividing data into training and test data.\n",
    "\n",
    "This will require splitting the powerproduction dataset with a 75%/25% ratio of training to test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split Method for Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Sklearn methods\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_csv(\"powerproduction.txt\") )\n",
    "\n",
    "# Reshape both columns to be 2D and name as x/y\n",
    "x = df[\"speed\"]\n",
    "x = x.values.reshape(500, 1)\n",
    "\n",
    "y = df[\"power\"]\n",
    "y = y.values\n",
    "\n",
    "#Split the dataset into Training set and Test Set, set test_size to\n",
    "# 2.5: train is 75% the size of the ful dataset and test is 25% the \n",
    "# size of full dataset and randomise with random_state(seed=0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                    test_size= 0.25, random_state=0)\n",
    "\n",
    "# Create model variable, set to LinearRegression() function\n",
    "# Use .fit() to adust weight of x and y data\n",
    "model = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "# Use the trained model to predict tests\n",
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the first 3 elements from each of the train/test arrays, we can see that the data is random_state() has randomised the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0:2], y_train[0:2], x_test[0:2], y_test[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Scatterlot of Training Data and Test Data With Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the y_predict line to show Sklearn Linear Regression line\n",
    "plt.plot(x_test, y_predict, color='r', label=\"Linear Regression\")\n",
    "\n",
    "# Plot the training data and format the plot\n",
    "plt.scatter(x_train, y_train, label=\"Training Data\", color='g', \n",
    "            alpha=.9)\n",
    "plt.scatter(x_test, y_test, label=\"Test Data\", color='y', alpha=.7)\n",
    "plt.legend()\n",
    "plt.title(\"Powerproduction: Train and Test Data\")\n",
    "plt.xlabel(\"Modelled Speed (Independent Variable)\")\n",
    "plt.ylabel(\"Modelled Power (Dependent Variable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save test/train variables to separate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = pd.DataFrame(x_train)\n",
    "x_test_1 = pd.DataFrame(x_test)\n",
    "y_train_1 = pd.DataFrame(y_train)\n",
    "y_test_1 = pd.DataFrame(y_test)\n",
    "y_predict_1 = pd.DataFrame(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1.to_csv('1_x_train.csv')\n",
    "x_test_1.to_csv('1_x_test.csv')\n",
    "y_train_1.to_csv('1_y_train.csv')\n",
    "y_test_1.to_csv('1_y_test.csv')\n",
    "y_predict_1.to_csv('1_y_predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Sklearn Model of SLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient\n",
    "\n",
    "The Coefficient of this model is 4.866:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model coefficient\n",
    "coefficient_2 = model.coef_\n",
    "print(\"Sklearn SLR Coefficient: \", coefficient_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data: Coefficient of Determination (R²)\n",
    "\n",
    "The R² of the training data is 72.2%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print R² of training data\n",
    "train_r_sq_2 = model.score(x_train, y_train)\n",
    "print(\"R² of Training Data: \", train_r_sq_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data: Coefficient of Determination (R²)\n",
    "\n",
    "Most importantly, the R² of the test data is 74.6% - this is the most important indicator of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print R² of test data\n",
    "test_r_sq_2 = model.score(x_test, y_test)\n",
    "print(\"R² Test Data:        \", test_r_sq_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A large degree of difference in the R² of the training data and that of the test data would indicate that there is an issue with the model. As this is less than 3%, it is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Advanced Results of Sklearn Model of SLR\n",
    "\n",
    "As we have used Sklearn to split our data and carry out Simple Linear Regression using a model, we can access extra statistics on our dataset.\n",
    "\n",
    "Below is a bloack of code that calls on the statsmodels.api() method to produce data including Std.Err, t-values and other datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api and math\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "# Load in test x array as U and load in first vector (0)\n",
    "# Create an empty list for y to be populated later\n",
    "U = x_test\n",
    "U_0 = 0\n",
    "y = []\n",
    "\n",
    "# Create a for loop with .append() to append the logarithm of each element \n",
    "# of x_test divided by 0, Eulers number, to y\n",
    "for i in U:\n",
    "    y.append(math.log(i/U_0, math.e))\n",
    "\n",
    "    # Set y to y_test\n",
    "y = y_test\n",
    "\n",
    "# Set t to y_predict and add a constant\n",
    "t = y_predict\n",
    "t = sm.add_constant(t, prepend=False)\n",
    "\n",
    "# Set model to the statsmodelapi summary, factoring in y and t as parameters\n",
    "model = sm.OLS(y,t)\n",
    "# Create result variable and set to the model already fit\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: The statistics of note below all relate to the x1 values, the constant values are being ignored in this model.\n",
    "\n",
    "#### Std. Err.\n",
    "\n",
    "As seen above the Standard Error of the coefficient is **0.055**.\n",
    "\n",
    "#### t-value (t)\n",
    "\n",
    "The t-value is x1 is **19.138**. As a high t-value is desirible, it is clear that a better model would result in a higher t-value.\n",
    "\n",
    "\n",
    "#### p-value\n",
    "\n",
    "The p-value is 0.\n",
    "\n",
    "#### Conclusion: The data (and graph) identify that this model *underfits* the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "# 4. Polynomial Linear Regression\n",
    "\n",
    "\n",
    "Two forms of Polynomial Regression will be carried out in this section.\n",
    "\n",
    "The first type will once again be an inaccurate regression on the full dataset. It will involve manually creating a Basis function that will them be fed as the parameter for Numpy's curve_fit() function.\n",
    "\n",
    "The second type will be a more accurate Sklearn regression model. The train_test_split() method will first split the data. Following this the x_train data will be fed into PolynomialFeatures() function (set to the 3rd degree). \n",
    "\n",
    "Finally the polynomial function will be fed into the LinearRegression() function and a prediction will be made.\n",
    "\n",
    "***\n",
    "\n",
    "## 4.1. Numpy's curve_fit(): Polynomial Regression on Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the basis function\n",
    "def basis(x, a, b, c):\n",
    "    return a * np.power(x, 7) + b * x**2 + c\n",
    "\n",
    "# choose the input and output variables\n",
    "x, y = df[\"speed\"], df[\"power\"]\n",
    "# curve fit\n",
    "exponents, _ = curve_fit(basis, x, y)\n",
    "# summarize the parameter values\n",
    "a, b, c = exponents\n",
    "\n",
    "# plot inputs and outputs\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "\n",
    "# Use np.arange to inputs from smallest vector to largest\n",
    "x_array = np.arange(min(x), max(x), 1)\n",
    "# calculate the output for the range\n",
    "y_array = basis(x_array, a, b, c)\n",
    "# create a line plot for the mapping function\n",
    "plt.plot(x_array, y_array, color='red')\n",
    "plt.title(\"Polynomial Regression Function on Full Dataset\")\n",
    "plt.xlabel(\"Speed\")\n",
    "plt.ylabel(\"Power\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Results\n",
    "\n",
    "#### Coefficients\n",
    "\n",
    "The basis function we created has the following form: **y = a * x + b * x^2 + c**\n",
    "\n",
    "Below, the exponents (a, b, c) are printed to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now factor these into the equation to determine the coefficients, or optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y = %.5f * x + %.5f * x^2 + %.5f'% (a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficents = **-0.0, 0.367. -6.771**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### R² of curve_fit() Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.corrcoef to caluclate R²\n",
    "np.corrcoef(x_array, y_array)[0, 1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above **suggests that this method has an R² of 91%**. But this is misleading.\n",
    "\n",
    "#### Conclusion: Similar to the poly_fit() Linear Regression, this curve_fit() method was conducted on the full dataset and not on trained data. As such, this R² cannot be relied upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## 4.2. Polynomial Regression Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import operator\n",
    "\n",
    "x = df[\"speed\"]\n",
    "y = df[\"power\"]\n",
    "y = y.values\n",
    "\n",
    "# Use old seeding method on numpy to provide random train and \n",
    "# test variables\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                    test_size= 0.25, random_state=0)\n",
    "\n",
    "# transform the data to include another axis\n",
    "x_train = x_train[:, np.newaxis]\n",
    "y_train = y_train[:, np.newaxis]\n",
    "x_test = x_test[:, np.newaxis]\n",
    "y_test = y_test[:, np.newaxis]\n",
    "\n",
    "y_train = y_train[x_train[:,0].argsort()]\n",
    "x_train = x_train[x_train[:, 0].argsort()]\n",
    "\n",
    "# Create variable featuring Polynomial of 3 degrees and fit to \n",
    "# the standardized features of x_train using .fit_transform()\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "x_poly = poly.fit_transform(x_train)\n",
    "\n",
    "# Assign model variable to LinearRegression()fitted with x_poly and y_train\n",
    "model_2 = LinearRegression().fit(x_poly, y_train)\n",
    "\n",
    "# Assign prediction variable to the prediction of x_poly\n",
    "y_poly_pred = model_2.predict(x_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save test/train variables to separate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = pd.DataFrame(x_train)\n",
    "x_test_2 = pd.DataFrame(x_test)\n",
    "y_train_2 = pd.DataFrame(y_train)\n",
    "y_test_2 = pd.DataFrame(y_test)\n",
    "x_poly_2 = pd.DataFrame(x_poly)\n",
    "y_poly_pred_2 = pd.DataFrame(y_poly_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2.to_csv('2_x_train.csv')\n",
    "x_test_2.to_csv('2_x_test.csv')\n",
    "y_train_2.to_csv('2_y_train.csv')\n",
    "y_test_2.to_csv('2_y_test.csv')\n",
    "x_poly_2.to_csv('2_x_poly.csv')\n",
    "y_poly_pred_2.to_csv('2_y_poly_pred_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Scatterplot of Polynomial Regression of Test/Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test data and training data on scatterplots\n",
    "plt.scatter(x_train, y_train, color='g', label=\"Training Data\", alpha=0.9)\n",
    "plt.scatter(x_test, y_test, color='y', label=\"Test Data\", alpha=0.9)\n",
    "\n",
    "# Plot zipped data for regression line and format with labels, legend\n",
    "# and title\n",
    "plt.plot(x_train, y_poly_pred, color='r', label=\"Polynomial (3 degrees)\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(\"Polynomial Regression on Test/Training Data\")\n",
    "plt.xlabel(\"Speed (Independent Variable)\")\n",
    "plt.ylabel(\"Power (Dependent Variable)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Sklearn Polynomial Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient\n",
    "\n",
    "There are 3 Coefficients of this model as it is a Polynomial of the 3rd degree, they are: -13.33, 1.94, -0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model coefficient\n",
    "coefficient_4 = model_2.coef_\n",
    "print(coefficient_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R² of PolynomialFeatures() Method\n",
    "\n",
    "The R² of this model is 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_2.score(x_poly, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Advanced Results of Sklearn Polynomial Regression Model\n",
    "\n",
    "As we have used Sklearn to split our data and carry out Simple Linear Regression using a model, we can access extra statistics on our dataset.\n",
    "\n",
    "Below is a bloack of code that calls on the statsmodels.api() method to produce data including Std.Err, t-values and other datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in test x array as U and load in first vector (0)\n",
    "# Create an empty list for y to be populated later\n",
    "U = x_train\n",
    "U_0 = 0\n",
    "y = []\n",
    "\n",
    "# Create a for loop with .append() to append the logarithm of each element \n",
    "# of x_train divided by 0, Eulers number, to y\n",
    "for number in U:\n",
    "    y.append(math.log(number/U_0, math.e))\n",
    "\n",
    "# Set y to y_test\n",
    "y = y_train\n",
    "\n",
    " # Set t to y_oly_pred and add a constant\n",
    "t = y_poly_pred\n",
    "t = sm.add_constant(t, prepend=False)\n",
    "\n",
    "# Set model to the statsmodelapi summary, factoring in y and t as parameters\n",
    "model = sm.OLS(y,t)\n",
    "result = model.fit()\n",
    "# Create result variable and set to model.fit and then call the summary() \n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: The statistics of note below all relate to the x1 values, the constant values are not included in the analysis.\n",
    "\n",
    "#### Std. Err.\n",
    "\n",
    "As seen above the Standard Error of the coefficient is **0.019**. This indicates that the Sklearn's PolynomialRegression() is a better fit than LinearRegression(), what was higher at 0.055. \n",
    "\n",
    "#### t-value (t)\n",
    "\n",
    "The t-value is x1 is **52.499**. As a high t-value is desirible, this is an improvement. Polynomial regression has produced a t-level that is more than 33 points higher than the Sklearn linear model.\n",
    "\n",
    "\n",
    "#### p-value\n",
    "\n",
    "The p-value is 0.\n",
    "\n",
    "#### Conclusion: The Sklearn Polynomial Regression fits the data well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "# 5. Table of Results \n",
    "\n",
    "|  | Data Used |Coef. |R²| Std.Err.*(x1)* | p-value*(x1)*  | t-value*(x1)*    | H0 Rejected |    | \n",
    "| :---| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| **Simple Linear Regression**   |   |    |    |    |    |   |    |      |\n",
    "|  *polyfit() Method* |Full Data | [4.917, -13.899] | 72.9%| ✘| ✘|✘ |✘  | \n",
    "| *Sklearn Model*  | Train/Test | 4.866 |   74.6% |0.055  |0.00 |19.128| ✔| \n",
    "|  | |    |    |   |   |    |    |   |  \n",
    "|  **Polynomial Regression**   |    |    |    |   |   |    |    |   |  \n",
    "| *curve_fit() Method*  | Full Data\t   |[-0.0, 0.367. -6.771]  |91.1% |✘   |✘   | ✘   | ✘| \n",
    "| *Sklearn Model* |  Train Test | [-13.332,   1.937,  -0.053] | 88.1% | 0.019  | 0.00  |52.499   | ✔| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
